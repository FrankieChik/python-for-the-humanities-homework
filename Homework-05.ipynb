{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Finish assignment 2 from the last homework. Here is the assignment text again:\n",
    "\n",
    "Create a class that represents a project (e.g. called Project). The class should have the following properties:\n",
    "\n",
    "* It should be initialized with a path to a directory that holds several folders.\n",
    "* It should have a list of collections objects (see below).\n",
    "* There should be a method called load_collections that will for each folder in the directory passed to the constructor, create a collection and name it according to the folder name and set the path to the folder in the collection.\n",
    "\n",
    "Create a class that represents a collection of texts (e.g. called Collection). The class should have the following properties:\n",
    "\n",
    "* A path to a folder in the filesystem.\n",
    "* A name for the collection.\n",
    "* a list of Text objects.\n",
    "* A method called load_files that will create a Text object for each file in the folder specified for the collection.\n",
    "\n",
    "Create a folder that has several subfolders. Each subfolder should have a year as name (e.g. 1991, 1992, 1993, ...). Put a couple of plain text files into each folder. Now create a Project object and initialize it with the path to the folder (that has the year subfolders). Now call load_collections on the project and load_files on each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1997, 1998, 2000, 2001]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'load_project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f5140a44469b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'load_project'"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "class Project:\n",
    "    def __init__(self, collectionspath):\n",
    "        self.path_to_collections=collectionspath\n",
    "    def load_collections(self):\n",
    "        print(\"loading\" + self.path_to_collections)\n",
    "\n",
    "class Collection(Project):\n",
    "    def __init__(self, filepath, name):\n",
    "        self.path_to_file=filepath\n",
    "        self.name=name\n",
    "    def load_files(self):\n",
    "        print(\"loading\" + self.path_to_file)\n",
    "\n",
    "import os\n",
    "all_files=[1997, 1998, 2000, 2001]\n",
    "for path, dirs, files in os.walk(\"/User/Documents/hinmingfrankiechik\"):\n",
    "    for file in files:\n",
    "        f1=Text(os.path.join(path, file), \"path\")\n",
    "        all_files.append(f)\n",
    "        print(filepath)\n",
    "print (all_files)\n",
    "for item in all_files:\n",
    "    f2=item.load_project()\n",
    "    print(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Write a function that reads and parses the JSON file in this directory called \"HW-05-data.json\". The file contains a list of references. For each entry in the list print the title, the authors, and the item type.\n",
    "\n",
    "Then let the user enter new entries (consisting of at least a title, an author, and an item type). Let the user enter as many entries as they like. Write the new entries as JSON into a new file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'items': [{'version': 38, 'title': '3 Elements Available in All TEI Documents - The TEI Guidelines', 'authors': [{'name': ' TEI Consortium', 'uri': None, 'localAuthorityId': None, 'firstName': '', 'lastName': 'TEI Consortium', 'positionInList': 0, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'WEBPAGE', 'publicationTitle': None, 'volume': None, 'issue': None, 'pages': None, 'date': '2015-01-01T00:00:00Z', 'dateFreetext': '2015', 'series': None, 'seriesTitle': None, 'url': 'http://www.tei-c.org/release/doc/tei-p5-doc/en/html/CO.html#COEDREG', 'abstractNote': '', 'accessDate': '2016-02-18T18:50:38Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': None, 'archiveLocation': None, 'libraryCatalog': None, 'callNumber': None, 'rights': '', 'dateAdded': '2016-02-18T18:50:38Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 32, 'title': 'Content Negotiation: why it is useful, and how to make it work', 'authors': [], 'editors': [], 'otherCreators': [], 'itemType': 'BLOG_POST', 'publicationTitle': None, 'volume': None, 'issue': None, 'pages': None, 'date': None, 'dateFreetext': '', 'series': None, 'seriesTitle': None, 'url': 'https://www.w3.org/blog/2006/02/content-negotiation/', 'abstractNote': 'We recently received a puzzled message from a visitor of the W3C Web site, asking how we were serving images without file suffix in their URI. Looking around, our visitor found that http://www.w3.org/StyleSheets/TR/logo-REC was not one file, but two: logo-REC.gif...', 'accessDate': '2016-02-18T18:22:03Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': 'Content Negotiation', 'archive': None, 'archiveLocation': None, 'libraryCatalog': None, 'callNumber': None, 'rights': '', 'dateAdded': '2016-02-18T18:22:03Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 15, 'title': 'Linked Data - Design Issues', 'authors': [{'name': 'Tim Berners-Lee', 'uri': None, 'localAuthorityId': None, 'firstName': 'Tim', 'lastName': 'Berners-Lee', 'positionInList': 0, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'WEBPAGE', 'publicationTitle': None, 'volume': None, 'issue': None, 'pages': None, 'date': '2006-01-01T00:00:00Z', 'dateFreetext': '2006', 'series': None, 'seriesTitle': None, 'url': 'https://www.w3.org/DesignIssues/LinkedData.html', 'abstractNote': '', 'accessDate': '2016-02-01T20:30:52Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': None, 'archiveLocation': None, 'libraryCatalog': None, 'callNumber': None, 'rights': '', 'dateAdded': '2016-02-01T20:30:52Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 34, 'title': 'Markup systems and the future of scholarly text processing', 'authors': [{'name': 'James H. Coombs', 'uri': None, 'localAuthorityId': None, 'firstName': 'James H.', 'lastName': 'Coombs', 'positionInList': 0, 'affiliations': None}, {'name': 'Allen H. Renear', 'uri': None, 'localAuthorityId': None, 'firstName': 'Allen H.', 'lastName': 'Renear', 'positionInList': 1, 'affiliations': None}, {'name': 'Steven J. DeRose', 'uri': None, 'localAuthorityId': None, 'firstName': 'Steven J.', 'lastName': 'DeRose', 'positionInList': 2, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'JOURNAL_ARTICLE', 'publicationTitle': 'Communications of the ACM', 'volume': '30', 'issue': '11', 'pages': '933-947', 'date': None, 'dateFreetext': '1987-11-1', 'series': '', 'seriesTitle': '', 'url': 'http://portal.acm.org/citation.cfm?doid=32206.32209', 'abstractNote': '', 'accessDate': '2016-02-18T18:49:45Z', 'seriesText': '', 'journalAbbreviation': '', 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': '', 'archiveLocation': '', 'libraryCatalog': 'CrossRef', 'callNumber': '', 'rights': '', 'dateAdded': '2016-02-18T18:49:45Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 7, 'title': 'Provenance and Annotation of Data and Processes - Springer', 'authors': [], 'editors': [], 'otherCreators': [], 'itemType': 'WEBPAGE', 'publicationTitle': None, 'volume': None, 'issue': None, 'pages': None, 'date': None, 'dateFreetext': '', 'series': None, 'seriesTitle': None, 'url': 'http://rd.springer.com/book/10.1007/978-3-642-17819-1/page/1', 'abstractNote': '', 'accessDate': '2013-09-02T20:54:15Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': None, 'archiveLocation': None, 'libraryCatalog': None, 'callNumber': None, 'rights': '', 'dateAdded': '2015-12-11T10:02:32Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 30, 'title': 'Provenance and Annotations for Linked Data', 'authors': [{'name': 'Kai Eckert', 'uri': None, 'localAuthorityId': None, 'firstName': 'Kai', 'lastName': 'Eckert', 'positionInList': 0, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'CONFERENCE_PAPER', 'publicationTitle': None, 'volume': '', 'issue': None, 'pages': '', 'date': None, 'dateFreetext': '', 'series': '', 'seriesTitle': None, 'url': '', 'abstractNote': '', 'accessDate': '', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': '', 'archiveLocation': '', 'libraryCatalog': '', 'callNumber': '', 'rights': '', 'dateAdded': '2016-02-18T16:32:52Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 18, 'title': 'RDF 1.1 Concepts and Abstract Syntax', 'authors': [{'name': ' W3C', 'uri': None, 'localAuthorityId': None, 'firstName': '', 'lastName': 'W3C', 'positionInList': 0, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'WEBPAGE', 'publicationTitle': None, 'volume': None, 'issue': None, 'pages': None, 'date': '2014-01-01T00:00:00Z', 'dateFreetext': '2014', 'series': None, 'seriesTitle': None, 'url': 'https://www.w3.org/TR/rdf11-concepts/', 'abstractNote': '', 'accessDate': '2016-02-01T21:37:56Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': None, 'archiveLocation': None, 'libraryCatalog': None, 'callNumber': None, 'rights': '', 'dateAdded': '2016-02-01T21:37:56Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 23, 'title': 'Representing Contextualized Data using Semantic Web Tools', 'authors': [{'name': 'Robert Macgregor', 'uri': None, 'localAuthorityId': None, 'firstName': 'Robert', 'lastName': 'Macgregor', 'positionInList': 0, 'affiliations': None}, {'name': 'In-Young Ko', 'uri': None, 'localAuthorityId': None, 'firstName': 'In-Young', 'lastName': 'Ko', 'positionInList': 1, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'CONFERENCE_PAPER', 'publicationTitle': None, 'volume': '', 'issue': None, 'pages': '', 'date': '2003-01-01T00:00:00Z', 'dateFreetext': '2003', 'series': '', 'seriesTitle': None, 'url': '', 'abstractNote': 'CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep Teregowda): Abstract: RDF-based tools promise to provide a base for reasoning about metadata and about situated data?data describing entities situated in time and space?that is superior to alternatives such as relational databases or object-oriented databases. However, essential representational machinery is missing from the current generation of Semantic Web tools and languages. When that machinery is added, the resulting capabilities offer a combination of novelty and flexibility that may usher in a wave of commercial Semantic Web tool-based applications that precedes the true arrival of the Semantic Web. We have constructed a system, the Semantic Engineering Workbench (SEW), that is proficient at managing situated data. Achieving a practical implementation necessitated extending the basic RDF tools (Hewlett-Packard?s Jena and Stanford?s Protégé) to support contexts. In the SEW, a context references a set of statements having common spatial, temporal (and other metadata) attributes. We investigated multiple possible implementations of contexts, and found significant drawbacks in the most common approaches. The clear winners are quads (adding a fourth field of type ?context ? to each triple results in a quadruple, or quad), and object-oriented contexts (a context mechanism that references individuals instead of statements). Most existing Semantic Web tools (e.g., Jena and Protégé) do not understand contextualized data. For these tools, object-oriented', 'accessDate': '2016-02-01T21:55:28Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': '', 'archiveLocation': '', 'libraryCatalog': 'citeseerx.ist.psu.edu', 'callNumber': '', 'rights': '', 'dateAdded': '2016-02-01T21:55:28Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 9, 'title': 'Term Extraction and Automatic Indexing', 'authors': [{'name': 'Christian Jacquemin', 'uri': None, 'localAuthorityId': None, 'firstName': 'Christian', 'lastName': 'Jacquemin', 'positionInList': 0, 'affiliations': None}, {'name': 'Didier Bourigault', 'uri': None, 'localAuthorityId': None, 'firstName': 'Didier', 'lastName': 'Bourigault', 'positionInList': 1, 'affiliations': None}, {'name': 'Ruslan Mitkov', 'uri': None, 'localAuthorityId': None, 'firstName': 'Ruslan', 'lastName': 'Mitkov', 'positionInList': 2, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'BOOK_SECTION', 'publicationTitle': None, 'volume': '', 'issue': None, 'pages': '', 'date': None, 'dateFreetext': '2005/01/13', 'series': '', 'seriesTitle': None, 'url': 'http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199276349.001.0001/oxfordhb-9780199276349-e-33', 'abstractNote': 'Terms are pervasive in scientific and technical documents and their identification is a crucial issue for any application dealing with the analysis, understanding, generation, or translation of such documents. In particular, the ever-growing mass of specialized documentation available on-line, in industrial and governmental archives or in digital libraries, calls for advances in terminology processing for tasks such as information retrieval, cross-language querying, indexing of multimedia documents, translation aids, document routing and summarization, etc. This article presents a new domain of research and development in natural language processing (NLP) that is concerned with the representation, acquisition, and recognition of terms. It begins with presenting the basic notions about the concept of ?terms?, ranging from the classical view, to the recent concepts. There are two main areas of research involving terminology in NLP, which are, term acquisition and term recognition. Finally, this article presents the recent advances and prospects in term acquisition and automatic indexing.', 'accessDate': '2016-01-04T07:55:24Z', 'seriesText': None, 'journalAbbreviation': None, 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': '', 'archiveLocation': '', 'libraryCatalog': 'www.oxfordhandbooks.com', 'callNumber': '', 'rights': '', 'dateAdded': '2016-01-04T08:12:21Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}, {'version': 4, 'title': 'The Anatomy of a Nanopublication', 'authors': [{'name': 'Paul Groth', 'uri': None, 'localAuthorityId': None, 'firstName': 'Paul', 'lastName': 'Groth', 'positionInList': 0, 'affiliations': None}, {'name': 'Andrew Gibson', 'uri': None, 'localAuthorityId': None, 'firstName': 'Andrew', 'lastName': 'Gibson', 'positionInList': 1, 'affiliations': None}, {'name': 'Jan Velterop', 'uri': None, 'localAuthorityId': None, 'firstName': 'Jan', 'lastName': 'Velterop', 'positionInList': 2, 'affiliations': None}], 'editors': [], 'otherCreators': [], 'itemType': 'JOURNAL_ARTICLE', 'publicationTitle': 'Information Services and Use', 'volume': '30', 'issue': '', 'pages': '51-56', 'date': '2010-01-01T00:00:00Z', 'dateFreetext': '2010', 'series': '', 'seriesTitle': '', 'url': '', 'abstractNote': '', 'accessDate': '', 'seriesText': '', 'journalAbbreviation': '', 'language': '', 'doi': None, 'issn': None, 'shortTitle': '', 'archive': '', 'archiveLocation': '', 'libraryCatalog': '', 'callNumber': '', 'rights': '', 'dateAdded': '2015-12-08T14:07:19Z', 'dateModified': None, 'conceptTags': None, 'references': None, 'extra': '', 'otherCreatorRoles': []}]}\n",
      "{'items': [{'title': 'Confucius beyond the Analects', 'authors': 'Michael Hunter', 'itemType': 'Monograph'}, {'title': 'Dividing the realm in order to govern: the spatial organization of the Song state, 960-1276 CE', 'authors': 'Ruth Mostern', 'itemType': 'Monograph'}]}\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "with open('HW-05-data.json', 'r') as f:\n",
    "    output = json.load(f)\n",
    "print(output)\n",
    "\n",
    "import json \n",
    "dictionary ={'items':[\n",
    "    {'title': 'Confucius beyond the Analects', \n",
    "    'authors': 'Michael Hunter', \n",
    "    'itemType': 'Monograph'\n",
    "    },\n",
    "    {'title': 'Dividing the realm in order to govern: the spatial organization of the Song state, 960-1276 CE',\n",
    "     'authors': 'Ruth Mostern',\n",
    "     'itemType': 'Monograph'\n",
    "    }\n",
    " ]\n",
    "            }\n",
    "json_object = json.dumps(dictionary, indent = 4) \n",
    "with open(\"sample.json\", \"w\") as f: \n",
    "    f.write(json_object) \n",
    "with open('sample.json', 'r') as f:\n",
    "    output = json.load(f)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "Create a file called README.md in your homework GitHub repository. Use Markdown to format the text on that page. You can put whatever text you like into the file, but it should contain at least:\n",
    "\n",
    "- multiple paragraphs of text\n",
    "- one heading\n",
    "- one subheading\n",
    "- one bullet point list\n",
    "- one numbered list\n",
    "- one link to another webpage\n",
    "- an italic and a bold word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no code here; add a new file to your GitHub repo instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Start working on your project and be ready to give a brief progress report in class next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I am working on topic modeling. The data I choose is text_files. I am now reading Topic modeling made just simple enough, The Stone and the Shell. \n",
    "and Collocations: identifying phrases that act like single words in natural language Processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
